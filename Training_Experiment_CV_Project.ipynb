{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "17ypKYrvhdhs-vDR6FFUcg7WnOT_f6JwQ",
      "authorship_tag": "ABX9TyOk8J+OcK+Jt+ulSDFJIlX1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DS-Dalen22/DedSec-Dalen/blob/main/Training_Experiment_CV_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Начало работы"
      ],
      "metadata": {
        "id": "AUv1QeMuQB67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Экспериментальный ноутбук**"
      ],
      "metadata": {
        "id": "ZrIC42PCHgEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l__OOjJ44_TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Citypersons.v9i.yolov8.zip .\n",
        "!unzip Citypersons.v9i.yolov8.zip"
      ],
      "metadata": {
        "id": "8S8RtNPOGJx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file = \"/content/Citypersons.v9i.yolov8.zip\"\n",
        "zip_path = \"/content/Citypersons.v9i.yolov8\""
      ],
      "metadata": {
        "id": "AEviUlr3GUEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Распаковка\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(zip_path)\n",
        "\n",
        "print(f\"Zip file '{zip_file}' has been extracted to '{zip_path}'\")"
      ],
      "metadata": {
        "id": "uYQw9HWfb0Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Вывод датасета по файлам и количества содержимых в нем изображений\n",
        "for root, dirs, files in os.walk(zip_path):\n",
        "  print(f\"Папка: {root}, Файлов: {len(files)}\")"
      ],
      "metadata": {
        "id": "VsZ1gc26cLkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создание переменных для файлов с изображениями и разметками уже разделенных на три выборки\n",
        "train_image_folder = '/content/Citypersons.v9i.yolov8/train/images/'\n",
        "train_label_folder = '/content/Citypersons.v9i.yolov8/train/labels/'\n",
        "\n",
        "val_image_folder = '/content/Citypersons.v9i.yolov8/valid/images/'\n",
        "val_label_folder = '/content/Citypersons.v9i.yolov8/valid/labels/'\n",
        "\n",
        "test_image_folder = '/content/Citypersons.v9i.yolov8/test/images/'\n",
        "test_label_folder = '/content/Citypersons.v9i.yolov8/test/labels/'"
      ],
      "metadata": {
        "id": "qI-meqbFesFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Пример вывода изображения и его метки\n",
        "train_images = os.listdir(train_image_folder)\n",
        "train_labels = os.listdir(train_label_folder)\n",
        "\n",
        "image_name = train_images[0]\n",
        "label_name = image_name.replace('.jpg', '.txt')\n",
        "\n",
        "print(f\"Изображение: {image_name}\")\n",
        "print(f\"Аннотация: {label_name}\")\n",
        "\n",
        "with open(os.path.join(train_label_folder, label_name), 'r') as label_file:\n",
        "    annotations = label_file.readlines()\n",
        "    for annotation in annotations:\n",
        "        print(annotation.strip())"
      ],
      "metadata": {
        "id": "MInWlla5jIVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from shutil import copyfile\n",
        "from PIL import Image\n",
        "from albumentations import (\n",
        "    Compose, OneOf, HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast, CLAHE, HueSaturationValue, RandomCrop, BboxParams\n",
        ")\n",
        "\n",
        "from albumentations import Compose\n",
        "import json"
      ],
      "metadata": {
        "id": "-MEnREpKURsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовительный этап, агументация данных библиотекой albumentations\n",
        "\n",
        "aug = Compose([\n",
        "    HorizontalFlip(p=0.5),\n",
        "    RandomBrightnessContrast(p=0.3),\n",
        "    HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5)\n",
        "], bbox_params=BboxParams(format='yolo', min_visibility=0.1))\n",
        "\n",
        "\n",
        "def augment_single_image(img_path, label_path, output_img_dir, output_label_dir):\n",
        "    \"\"\"\n",
        "    Функция для аугментации одного изображения и соответствующих ему разметок (боксов).\n",
        "    - img_path: путь к исходному изображению\n",
        "    - label_path: путь к файлу с разметкой (YOLO формат)\n",
        "    - output_img_dir: куда сохранить аугментированное изображение\n",
        "    - output_label_dir: куда сохранить обновлённую разметку\n",
        "    \"\"\"\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    bboxes = []\n",
        "    for line in lines:\n",
        "        class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "        bboxes.append([x_center, y_center, width, height])\n",
        "\n",
        "    if bboxes:\n",
        "        augmented = aug(image=img, bboxes=bboxes)\n",
        "        aug_img = augmented['image']\n",
        "        aug_bboxes = augmented['bboxes']\n",
        "    else:\n",
        "        aug_img = img\n",
        "        aug_bboxes = []\n",
        "\n",
        "    os.makedirs(output_img_dir, exist_ok=True)\n",
        "    os.makedirs(output_label_dir, exist_ok=True)\n",
        "\n",
        "    output_img_path = os.path.join(output_img_dir, os.path.basename(img_path))\n",
        "    cv2.imwrite(output_img_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    output_label_path = os.path.join(output_label_dir, os.path.basename(label_path))\n",
        "    with open(output_label_path, 'w') as f:\n",
        "        for bbox in aug_bboxes:\n",
        "            f.write(f\"0 {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\")  # class_id=0 (person)\n",
        "\n",
        "\n",
        "input_image_dir = \"/content/Citypersons.v9i.yolov8/train/images/\"\n",
        "input_label_dir = \"/content/Citypersons.v9i.yolov8/train/labels/\"\n",
        "output_image_dir = \"/content/train/augmented/images\"\n",
        "output_label_dir = \"/content/train/augmented/labels\"\n",
        "\n",
        "for img_name in os.listdir(input_image_dir):\n",
        "    if img_name.endswith('.jpg'):\n",
        "        img_path = os.path.join(input_image_dir, img_name)\n",
        "        label_path = os.path.join(input_label_dir, img_name.replace('.jpg', '.txt'))\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            augment_single_image(img_path, label_path, output_image_dir, output_label_dir)\n",
        "\n",
        "print(\"Аугментация завершена\")\n"
      ],
      "metadata": {
        "id": "sKDIdZAZegfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример вывода изображения\n",
        "from IPython.display import Image, display\n",
        "display(Image(os.path.join(output_image_dir, os.listdir(output_image_dir)[0])))"
      ],
      "metadata": {
        "id": "aopTQukeI2fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def draw_bboxes(image_path, label_path):\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "\n",
        "    for line in lines:\n",
        "        class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "        x1 = int((x_center - width/2) * w)\n",
        "        y1 = int((y_center - height/2) * h)\n",
        "        x2 = int((x_center + width/2) * w)\n",
        "        y2 = int((y_center + height/2) * h)\n",
        "\n",
        "\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    cv2_imshow(img)\n",
        "    return img\n",
        "\n",
        "original_img_name = os.listdir(\"/content/Citypersons.v9i.yolov8/train/images\")[0]\n",
        "original_img_path = os.path.join(\"/content/Citypersons.v9i.yolov8/train/images\", original_img_name)\n",
        "original_label_path = os.path.join(\"/content/Citypersons.v9i.yolov8/train/labels\", original_img_name.replace('.jpg', '.txt'))\n",
        "\n",
        "\n",
        "augmented_img_path = os.path.join(\"/content/train/augmented/images\", original_img_name)\n",
        "augmented_label_path = os.path.join(\"/content/train/augmented/labels\", original_img_name.replace('.jpg', '.txt'))\n",
        "\n",
        "print(\"Оригинальное изображение:\")\n",
        "original_img = draw_bboxes(original_img_path, original_label_path)\n",
        "\n",
        "print(\"\\nАугментированное изображение:\")\n",
        "if os.path.exists(augmented_img_path):\n",
        "    augmented_img = draw_bboxes(augmented_img_path, augmented_label_path)\n",
        "else:\n",
        "    print(\"Ошибка\")"
      ],
      "metadata": {
        "id": "he7Ui3MmJGN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "\n",
        "train_images = os.listdir(\"/content/Citypersons.v9i.yolov8/train/images\")[:5]\n",
        "display(Markdown(\"**Train images:** \" + \", \".join(train_images)))\n",
        "\n",
        "with open(f\"/content/Citypersons.v9i.yolov8/train/labels/{train_images[1].replace('.jpg', '.txt')}\", \"r\") as f:\n",
        "    display(Markdown(\"**Пример аннотации:**\\n```\\n\" + f.read() + \"\\n```\"))"
      ],
      "metadata": {
        "id": "Kc-zCKVnGdqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "cgmCONdYzbXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Первый запуск обучения. Использовалась архитектура Yolo nano, оптимизатор по умолчанию, weight_decay - чтобы исключить переобучение. Также кастомные настройки гиперпараметров Yolo"
      ],
      "metadata": {
        "id": "gG6ZShbRwDMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt')\n",
        "model.train(\n",
        "    data='data.yaml',\n",
        "    epochs=100,\n",
        "    batch=8,\n",
        "    lr0=0.01,\n",
        "    lrf=0.1,\n",
        "    optimizer='AdamW',\n",
        "    weight_decay=0.0005,\n",
        "    hsv_h=0.2,\n",
        "    hsv_s=0.7,\n",
        "    flipud=0.3,\n",
        "    fliplr=0.5,\n",
        "    name='yolo_custom_aug'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "x3xmBSdisKN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод графиков"
      ],
      "metadata": {
        "id": "LuEDNu46xH_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.open('runs/detect/yolo_custom_aug/results.png')"
      ],
      "metadata": {
        "id": "qhrL_kQg_VNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* При выводе метрик recall который отвечает за то чтобы модель находила людей равен всего 50% - много пропусков.\n",
        "\n",
        "Точность определения человека (Precision) - 70%\n",
        "\n",
        "mAP@50 0.60 - общая точность нормальная\n",
        "mAP@50-95 0.36 - рамки довольно неточные"
      ],
      "metadata": {
        "id": "SHLpsDg9xPyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('runs/detect/yolo_custom_aug/weights/best.pt')\n",
        "\n",
        "metrics = model.val()\n",
        "\n",
        "print(\"Результаты валидации:\")\n",
        "print(f\"Precision всех классов: {metrics.box.p.mean():.2f}\")\n",
        "print(f\"Recall всех классов: {metrics.box.r.mean():.2f}\")\n",
        "print(f\"mAP@50: {metrics.box.map50:.2f}\")\n",
        "print(f\"mAP@50-95: {metrics.box.map:.2f}\")"
      ],
      "metadata": {
        "id": "Cx58Xm7E_edP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Второй запуск обучения. Модель nano\n",
        "\n",
        "оптимизатор SGD\n",
        "\n",
        "Batch 16"
      ],
      "metadata": {
        "id": "SjYQgde1yqwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = '/content/drive/MyDrive/yolo_training'\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "model.train(\n",
        "    data='data.yaml',\n",
        "    epochs=100,\n",
        "    batch=16,\n",
        "    lr0=0.001,\n",
        "    lrf=0.1,\n",
        "    optimizer='SGD',\n",
        "    weight_decay=0.0005,\n",
        "    hsv_h=0.2,\n",
        "    hsv_s=0.7,\n",
        "    fliplr=0.5,\n",
        "    name='yolo_custom_aug2',\n",
        "    project=SAVE_PATH\n",
        ")\n"
      ],
      "metadata": {
        "id": "xqq_W5KTFg6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open('/content/drive/MyDrive/yolo_training/yolo_custom_aug2/results.png')"
      ],
      "metadata": {
        "id": "jnAWH0tlZgqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты практически идентичны с первым запуском"
      ],
      "metadata": {
        "id": "9e_7GX05zz0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('/content/drive/MyDrive/yolo_training/yolo_custom_aug2/weights/best.pt')\n",
        "\n",
        "\n",
        "metrics = model.val()\n",
        "\n",
        "\n",
        "print(\"Результаты валидации:\")\n",
        "print(f\"Precision всех классов: {metrics.box.p.mean():.2f}\")\n",
        "print(f\"Recall всех классов: {metrics.box.r.mean():.2f}\")\n",
        "print(f\"mAP@50: {metrics.box.map50:.2f}\")\n",
        "print(f\"mAP@50-95: {metrics.box.map:.2f}\")"
      ],
      "metadata": {
        "id": "YUSiqZYsdYDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Третий запуск обучения.\n",
        "\n",
        "Сталкиваюсь с проблемой ограниченных ресурсов Google Collab\n",
        "\n",
        "Изучив вариации размеров архитектур YOLO перехожу на (M)\n",
        "\n",
        "Batch выставлен на 4 чтобы попробовать ускорить процесс поскольку imgsize установлен на 960. На тот момент также думал что это позволит увеличить точность\n",
        "\n",
        "Оптимизатор по умолчанию YoloV8"
      ],
      "metadata": {
        "id": "T-Mwv62G0YWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "model.train(\n",
        "    data='data.yaml',\n",
        "    epochs=40,\n",
        "    batch=4,\n",
        "    imgsz=960,\n",
        "    lr0=0.003,\n",
        "    lrf=0.1,\n",
        "    optimizer='AdamW',\n",
        "    weight_decay=0.001,\n",
        "    hsv_h=0.1,\n",
        "    hsv_s=0.7,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    patience=20,\n",
        "    project='runs/detect',\n",
        "    name='yolov8m_custom960',\n",
        "    exist_ok=True,\n",
        "    resume=False\n",
        ")"
      ],
      "metadata": {
        "id": "GBgru4qmI1tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Второй пайплайн"
      ],
      "metadata": {
        "id": "4GqtT3D5QS6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Проанализировав прошлую работу я решаю проверить свой датасет а также провожу консультацию после которой понимаю что входящих изображений слишком мало и они слишком однообразны. Тажке полностью переделываю аугментацию\n",
        "\n",
        "* К основному датасету я добавляю еще один новый что суммарно увеличило мои изображения вдвое а также новый датасет содержал разнообразие что должно было исправить проблему слабого Recall"
      ],
      "metadata": {
        "id": "9hlto5IqdLLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "from google.colab import files\n",
        "from shutil import copy2"
      ],
      "metadata": {
        "id": "Bc0CuBiyensF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bAV9bgB5epMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/human.v1i.yolov8.zip .\n",
        "!cp /content/drive/MyDrive/Citypersons.v9i.yolov8.zip ."
      ],
      "metadata": {
        "id": "Skql3olseq90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o Citypersons.v9i.yolov8.zip -d /content/citypersons\n",
        "!unzip -o human.v1i.yolov8.zip -d /content/human_dataset"
      ],
      "metadata": {
        "id": "0NPABxWQes18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Функция комбинирования датасетов*\n",
        "\n",
        "* Скрипт создает структуру combined_dataset и собирает туда картинки/лейблы из двух источников с префиксами, чтобы избежать коллизий имён.\n",
        "\n",
        "* ensure_test_split — если нет test, создаёт его, перемещая ratio часть train в test.\n",
        "\n",
        "* check_labels — быстрая валидация аннотаций: формат строк, общее число боксов, и подсчёт «очень маленьких» боксов."
      ],
      "metadata": {
        "id": "DxDZQY9IGq-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Изменения №1"
      ],
      "metadata": {
        "id": "hrpfqeRdOwZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*обратная связь по проекту*\n",
        "\n",
        "Что изменилось?\n",
        "* функция для комбинирования датасета была перепроверена на наличие ошибок с лейблами и вторым датасетом. Поскольку структура датасета human отличалась отсутствием test выборки, функция def ensure_test_split создает test/images test/labels папки путем случайного поднабора данных из train - 15%.\n",
        "\n",
        "* Функция merge_datasets для каждого изображения копирует его в целевую папку tgt_img с новой именной prefix_originalname (например city_img001.jpg), чтобы избежать коллизий имён при мердже разных наборов.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-dacdNY3vZEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, random, shutil\n",
        "from shutil import copy2\n",
        "\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    os.makedirs(f\"/content/combined_dataset/{split}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"/content/combined_dataset/{split}/labels\", exist_ok=True)\n",
        "\n",
        "\n",
        "def ensure_test_split(base_dir, ratio=0.15):\n",
        "    train_img_dir = os.path.join(base_dir, \"train\", \"images\")\n",
        "    train_lbl_dir = os.path.join(base_dir, \"train\", \"labels\")\n",
        "    test_img_dir = os.path.join(base_dir, \"test\", \"images\")\n",
        "    test_lbl_dir = os.path.join(base_dir, \"test\", \"labels\")\n",
        "\n",
        "    if os.path.exists(test_img_dir):\n",
        "        print(f\"[INFO] test уже существует в {base_dir}\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(test_img_dir, exist_ok=True)\n",
        "    os.makedirs(test_lbl_dir, exist_ok=True)\n",
        "\n",
        "    all_imgs = glob.glob(os.path.join(train_img_dir, \"*.*\"))\n",
        "    test_size = int(len(all_imgs) * ratio)\n",
        "    test_imgs = random.sample(all_imgs, test_size)\n",
        "\n",
        "    for img_path in test_imgs:\n",
        "        fname = os.path.basename(img_path)\n",
        "        base = os.path.splitext(fname)[0]\n",
        "        lbl_path = os.path.join(train_lbl_dir, base + \".txt\")\n",
        "\n",
        "        shutil.move(img_path, os.path.join(test_img_dir, fname))\n",
        "        if os.path.exists(lbl_path):\n",
        "            shutil.move(lbl_path, os.path.join(test_lbl_dir, base + \".txt\"))\n",
        "\n",
        "    print(f\"[INFO] Создали test в {base_dir}: {test_size} файлов\")\n",
        "\n",
        "\n",
        "def merge_datasets(src_img, src_lbl, tgt_img, tgt_lbl, prefix):\n",
        "    if not os.path.exists(src_img):\n",
        "        print(f\"[WARN] Папки {src_img} нет — пропускаем\")\n",
        "        return\n",
        "\n",
        "    valid_exts = ('.jpg', '.jpeg', '.png', '.JPG')\n",
        "    for fname in os.listdir(src_img):\n",
        "        if fname.lower().endswith(valid_exts):\n",
        "            base = os.path.splitext(fname)[0]\n",
        "            src_img_path = os.path.join(src_img, fname)\n",
        "            src_lbl_path = os.path.join(src_lbl, base + \".txt\")\n",
        "\n",
        "            new_img_name = f\"{prefix}_{fname}\"\n",
        "            new_lbl_name = f\"{prefix}_{base}.txt\"\n",
        "\n",
        "            copy2(src_img_path, os.path.join(tgt_img, new_img_name))\n",
        "            if os.path.exists(src_lbl_path):\n",
        "                copy2(src_lbl_path, os.path.join(tgt_lbl, new_lbl_name))\n",
        "            else:\n",
        "                open(os.path.join(tgt_lbl, new_lbl_name), \"w\").close()\n",
        "                print(f\"[INFO] У {fname} нет лейбла → создали пустой .txt\")\n",
        "\n",
        "\n",
        "ensure_test_split(\"/content/human_dataset\", ratio=0.15)\n",
        "\n",
        "# citypersons\n",
        "merge_datasets('/content/citypersons/train/images', '/content/citypersons/train/labels',\n",
        "               '/content/combined_dataset/train/images', '/content/combined_dataset/train/labels', prefix=\"city\")\n",
        "merge_datasets('/content/citypersons/valid/images', '/content/citypersons/valid/labels',\n",
        "               '/content/combined_dataset/valid/images', '/content/combined_dataset/valid/labels', prefix=\"city\")\n",
        "merge_datasets('/content/citypersons/test/images', '/content/citypersons/test/labels',\n",
        "               '/content/combined_dataset/test/images', '/content/combined_dataset/test/labels', prefix=\"city\")\n",
        "\n",
        "# human\n",
        "merge_datasets('/content/human_dataset/train/images', '/content/human_dataset/train/labels',\n",
        "               '/content/combined_dataset/train/images', '/content/combined_dataset/train/labels', prefix=\"human\")\n",
        "merge_datasets('/content/human_dataset/valid/images', '/content/human_dataset/valid/labels',\n",
        "               '/content/combined_dataset/valid/images', '/content/combined_dataset/valid/labels', prefix=\"human\")\n",
        "merge_datasets('/content/human_dataset/test/images', '/content/human_dataset/test/labels',\n",
        "               '/content/combined_dataset/test/images', '/content/combined_dataset/test/labels', prefix=\"human\")\n",
        "\n",
        "\n",
        "def list_files(d, exts=('.jpg','.png','.jpeg','.JPG')):\n",
        "    return [os.path.basename(p) for p in glob.glob(os.path.join(d,'*')) if p.lower().endswith(exts)]\n",
        "\n",
        "def check_labels(lbl_dir):\n",
        "    problems = []\n",
        "    stats = {'total_lbl_files':0, 'total_boxes':0, 'tiny_boxes':0}\n",
        "    for f in os.listdir(lbl_dir):\n",
        "        if not f.endswith('.txt'): continue\n",
        "        stats['total_lbl_files'] += 1\n",
        "        with open(os.path.join(lbl_dir, f), \"r\") as fh:\n",
        "            lines = fh.read().strip().splitlines()\n",
        "        for L in lines:\n",
        "            parts = L.split()\n",
        "            if len(parts) != 5:\n",
        "                problems.append((f, 'bad_line', L))\n",
        "                continue\n",
        "            cls,x,y,w,h = map(float, parts)\n",
        "            stats['total_boxes'] += 1\n",
        "            if w*h < 0.0005:\n",
        "                stats['tiny_boxes'] += 1\n",
        "    return stats, problems[:10]\n",
        "\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "for split in splits:\n",
        "    img_dir = f\"/content/combined_dataset/{split}/images\"\n",
        "    lbl_dir = f\"/content/combined_dataset/{split}/labels\"\n",
        "    imgs = list_files(img_dir)\n",
        "    print(f\"{split} imgs: {len(imgs)}\")\n",
        "    print(f\"{split} label check:\", check_labels(lbl_dir))\n",
        "    print(\"-\"*40)"
      ],
      "metadata": {
        "id": "1u_-LLc9mzCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations"
      ],
      "metadata": {
        "id": "UMxtQ-0me6FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Новый код аугментации\n",
        "\n",
        "Этот код предназначен для увеличения разнообразия датасета с помощью аугментаций. Каждое изображение и его метка проходят через набор случайных трансформаций, после чего сохраняются новые варианты изображений вместе с обновлёнными координатами bbox.\n",
        "\n",
        "\n",
        "* bbox_params - обновляет координаты всех bbox после каждой трансформации\n",
        "\n",
        "* N_AUGS = 1  перебирает все изображения в папке, находит к ним .txt аннотации и применяет аугментации. Для каждой картинки создаётся N_AUGS новых вариантов - в моем случае (1) - что удваивает мой датасет\n",
        "\n",
        "* Каждое аугментированное изображение сохраняется в папку out_img_dir.\n",
        "Его разметка сохраняется в .txt файл в папку out_lbl_dir.\n",
        "* Если после аугментации боксы исчезли (объект полностью вышел за кадр) - создаётся пустой .txt файл."
      ],
      "metadata": {
        "id": "H6Oi2TgB5woW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Изменения №2"
      ],
      "metadata": {
        "id": "Lre8ZsImOm9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Обратная связь по проекту*\n",
        "\n",
        "Изменения:\n",
        "\n",
        "* убрал излишний resize\n",
        "* min_visibility=0.05\n",
        "* аугментированные копии сохраняются отдельно в train_aug и в дальнейшем к ним идет обращение через конф.файл"
      ],
      "metadata": {
        "id": "r0JFEq8UG-Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, CLAHE, RandomBrightnessContrast,\n",
        "    HueSaturationValue, RandomScale, MotionBlur,\n",
        "    BboxParams\n",
        ")\n",
        "\n",
        "\n",
        "N_AUGS = 1\n",
        "\n",
        "\n",
        "aug = Compose(\n",
        "    [\n",
        "        HorizontalFlip(p=0.5),\n",
        "        CLAHE(clip_limit=4.0, p=0.3),\n",
        "        RandomBrightnessContrast(p=0.5),\n",
        "        HueSaturationValue(hue_shift_limit=15, sat_shift_limit=20, val_shift_limit=15, p=0.5),\n",
        "        RandomScale(scale_limit=(-0.2, 0.6), p=0.4),\n",
        "        MotionBlur(blur_limit=7, p=0.3),\n",
        "    ],\n",
        "    bbox_params=BboxParams(\n",
        "        format='yolo',\n",
        "        min_visibility=0.05,\n",
        "        clip=True,\n",
        "        label_fields=['class_labels']\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "input_img_dir = \"/content/combined_dataset/train/images\"\n",
        "input_lbl_dir = \"/content/combined_dataset/train/labels\"\n",
        "out_img_dir   = \"/content/combined_dataset/train_aug/images\"\n",
        "out_lbl_dir   = \"/content/combined_dataset/train_aug/labels\"\n",
        "\n",
        "os.makedirs(out_img_dir, exist_ok=True)\n",
        "os.makedirs(out_lbl_dir, exist_ok=True)\n",
        "\n",
        "valid_ext = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "\n",
        "\n",
        "def augment_single_image(img_path, label_path, out_img_dir, out_lbl_dir, n_augs):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"Не удалось прочитать {img_path}\")\n",
        "        return\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    bboxes, class_ids = [], []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 5:\n",
        "                class_id, x, y, w, h = map(float, parts)\n",
        "                bboxes.append([x, y, w, h])\n",
        "                class_ids.append(int(class_id))\n",
        "\n",
        "    base_name, ext = os.path.splitext(os.path.basename(img_path))\n",
        "\n",
        "    for i in range(1, n_augs + 1):\n",
        "        if bboxes:\n",
        "            augmented = aug(image=img_rgb, bboxes=bboxes, class_labels=class_ids)\n",
        "            aug_img_rgb = augmented['image']\n",
        "            aug_bboxes = augmented['bboxes']\n",
        "            aug_classes = augmented['class_labels']\n",
        "        else:\n",
        "            aug_img_rgb, aug_bboxes, aug_classes = img_rgb, [], []\n",
        "\n",
        "\n",
        "        out_img_name = f\"{base_name}_aug{i}.jpg\"\n",
        "        out_lbl_name = f\"{base_name}_aug{i}.txt\"\n",
        "\n",
        "\n",
        "        output_img_path = os.path.join(out_img_dir, out_img_name)\n",
        "        output_lbl_path = os.path.join(out_lbl_dir, out_lbl_name)\n",
        "\n",
        "\n",
        "        cv2.imwrite(output_img_path, cv2.cvtColor(aug_img_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "\n",
        "        if aug_bboxes:\n",
        "            with open(output_lbl_path, 'w') as f:\n",
        "                for cls, (x, y, w, h) in zip(aug_classes, aug_bboxes):\n",
        "                    f.write(f\"{cls} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "        else:\n",
        "            open(output_lbl_path, 'w').close()\n",
        "\n",
        "\n",
        "\n",
        "for img_name in tqdm(os.listdir(input_img_dir), desc=\"Augmenting\"):\n",
        "    if img_name.lower().endswith(valid_ext):\n",
        "        img_path = os.path.join(input_img_dir, img_name)\n",
        "        label_path = os.path.join(input_lbl_dir, os.path.splitext(img_name)[0] + '.txt')\n",
        "        augment_single_image(img_path, label_path, out_img_dir, out_lbl_dir, n_augs=N_AUGS)\n",
        "\n",
        "\n",
        "num_imgs = len([f for f in os.listdir(out_img_dir) if f.lower().endswith(valid_ext)])\n",
        "num_lbls = len([f for f in os.listdir(out_lbl_dir) if f.endswith('.txt')])\n",
        "\n",
        "print(f\"Аугментация завершена!\")\n",
        "print(f\"Создано изображений: {num_imgs}\")\n",
        "print(f\"Создано лейблов: {num_lbls}\")\n"
      ],
      "metadata": {
        "id": "N3vENbJj-hUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяю количество данных. в общем выходит 10.109 изображений"
      ],
      "metadata": {
        "id": "Sxl_CgnfIWOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train:\", len(os.listdir(\"/content/combined_dataset/train/images\")))\n",
        "print(\"train_aug:\", len(os.listdir(\"/content/combined_dataset/train_aug/images\")))\n",
        "print(\"valid:\", len(os.listdir(\"/content/combined_dataset/valid/images\")))\n",
        "print(\"test:\", len(os.listdir(\"/content/combined_dataset/test/images\")))"
      ],
      "metadata": {
        "id": "blHMxMVf7nYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Подготовка конфигурационного файла"
      ],
      "metadata": {
        "id": "RrnEjXH5-Jn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml = \"\"\"\n",
        "train:\n",
        "  - /content/combined_dataset/train/images\n",
        "  - /content/combined_dataset/train_aug/images\n",
        "\n",
        "val: /content/combined_dataset/valid/images\n",
        "test: /content/combined_dataset/test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['person']\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/data.yaml\", \"w\") as f:\n",
        "    f.write(data_yaml)"
      ],
      "metadata": {
        "id": "h8qm6WNhfCsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ojh80XH3guLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "iKwXfy7KfEWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3 обучение YOLOv8s."
      ],
      "metadata": {
        "id": "09_EZqPe-VX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = '/content/drive/MyDrive/yolo_training'\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8s.pt')\n",
        "model.train(\n",
        "    data='/content/data.yaml',\n",
        "    epochs=120,\n",
        "    batch=8,\n",
        "    imgsz=640,\n",
        "    optimizer='AdamW',\n",
        "    hsv_h=0.015,\n",
        "    mosaic=0.5,\n",
        "    name='DetectModelS',\n",
        "    project=SAVE_PATH,\n",
        "    save_period=50\n",
        ")"
      ],
      "metadata": {
        "id": "2ZgO155lHI-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "По результатам обучения наблюдается рост метрик\n",
        "\n",
        "* Precision: 0.76 → 0.83 (модель реже делает ложные срабатывания).\n",
        "\n",
        "* Recall: 0.50 → 0.54 (чуть лучше находит людей, но прирост небольшой).\n",
        "\n",
        "* mAP@50: 0.60 → 0.66 (общее качество детекции выросло).\n",
        "\n",
        "* mAP@50-95: 0.36 → 0.41 (модель стабильнее работает на разных IoU порогах).\n",
        "\n",
        "Вывод:\n",
        "\n",
        "Аугментация и переработка датасета сработали и модель стала аккуратнее и внимательнее.\n",
        "\n",
        "Основной рывок в mAP благодаря тому что данные стали разнообразнее.\n",
        "\n",
        "Recall не получил сильного прироста поскольку требует датасет свыше 10к изображений."
      ],
      "metadata": {
        "id": "snJBYmss_wV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New experiments"
      ],
      "metadata": {
        "id": "31OlRnx2OZXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Обратная связь по проекту. Последние обучения 1/2.*\n",
        "\n",
        "Изменения:\n",
        "* большинство параметров yolo оставляю по умолчанию.\n",
        "* Добавляю patience\n",
        "* Используется Collab Pro обучение на гп А100 с увеличенным объемом ОЗУ\n",
        "* imgsz 640"
      ],
      "metadata": {
        "id": "j7O9dayoI2jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = '/content/drive/MyDrive/yolo_training'\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8m.pt')\n",
        "model.train(\n",
        "    data='/content/data.yaml',\n",
        "    epochs=200,\n",
        "    batch=32,\n",
        "    name='UpdatedModel',\n",
        "    project=SAVE_PATH,\n",
        "    save_period=50,\n",
        "    patience=30\n",
        ")"
      ],
      "metadata": {
        "id": "iKJSrkjLAMXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты валидации:\n",
        "* Precision всех классов: 0.85\n",
        "* Recall всех классов: 0.58\n",
        "* mAP@50: 0.69\n",
        "* mAP@50-95: 0.45\n",
        "\n",
        "Рост метрик засчет исправленой ошибки на этапе комбинирования датасета + изменение кода аугментации + стандартные параметры обучения Yolo.\n",
        "\n",
        "Обучение завершилось на 117 эпохе (Patience)"
      ],
      "metadata": {
        "id": "r-OogJ0aJrXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "\n",
        "\n",
        "print(\"Результаты валидации:\")\n",
        "print(f\"Precision всех классов: {metrics.box.p.mean():.2f}\")\n",
        "print(f\"Recall всех классов: {metrics.box.r.mean():.2f}\")\n",
        "print(f\"mAP@50: {metrics.box.map50:.2f}\")\n",
        "print(f\"mAP@50-95: {metrics.box.map:.2f}\")"
      ],
      "metadata": {
        "id": "pTmJlKlUlFQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Последнее обучение"
      ],
      "metadata": {
        "id": "XvhQMrwMQh6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Обратная связь по проекту. Обучение 2/2.*\n",
        "\n",
        "* patience=40\n",
        "* imgsz=960"
      ],
      "metadata": {
        "id": "1DFdyAVQKYg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = '/content/drive/MyDrive/yolo_training'\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8m.pt')\n",
        "model.train(\n",
        "    data='/content/data.yaml',\n",
        "    epochs=200,\n",
        "    imgsz=960,\n",
        "    batch=16,\n",
        "    name='SecondUpdatedModel',\n",
        "    project=SAVE_PATH,\n",
        "    patience=40\n",
        ")"
      ],
      "metadata": {
        "id": "CJnH0Q4NbRky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты валидации:\n",
        "* Precision всех классов: 0.85 (без изменений)\n",
        "* Recall всех классов: 0.65 > 0.58\n",
        "* mAP@50: 0.76 > 0.69\n",
        "* mAP@50-95: 0.51 > 0.45\n",
        "\n",
        "\n",
        "обучение завершилось на 51 эпохе - patience=40"
      ],
      "metadata": {
        "id": "HV4geJMsK2YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "\n",
        "\n",
        "print(\"Результаты валидации:\")\n",
        "print(f\"Precision всех классов: {metrics.box.p.mean():.2f}\")\n",
        "print(f\"Recall всех классов: {metrics.box.r.mean():.2f}\")\n",
        "print(f\"mAP@50: {metrics.box.map50:.2f}\")\n",
        "print(f\"mAP@50-95: {metrics.box.map:.2f}\")"
      ],
      "metadata": {
        "id": "9EDlTv04ATyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Вывод графиков"
      ],
      "metadata": {
        "id": "fq0sKUBdBdBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "results_path = '/content/drive/MyDrive/yolo_training/DetectModelS3'\n",
        "\n",
        "for fname in os.listdir(results_path):\n",
        "    if fname.endswith('.png'):\n",
        "        print(fname)\n",
        "        display(Image(os.path.join(results_path, fname)))"
      ],
      "metadata": {
        "id": "I7ZFDj4x0uNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "wtve-wo3fMkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lmYFhzgY5ZGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/FinalProject/notebooks/DetectModelS3best.pt ."
      ],
      "metadata": {
        "id": "zP9AL0tF2PDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/yolo_training/SecondUpdatedModel/weights/best.pt ."
      ],
      "metadata": {
        "id": "lfbjiokqAkbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U python-telegram-bot==22.3"
      ],
      "metadata": {
        "id": "vofG7Y8ESLmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from ultralytics import YOLO\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters"
      ],
      "metadata": {
        "id": "FHWdlcxnEfd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Использую библиотеки для создания телеграм бота\n",
        "\n",
        "nest_asyncio позволяет \"поверх\" существующего цикла запускать новые асинхронные процессы, поэтому бот может работать в среде\n",
        "\n",
        "Логика работы:\n",
        "\n",
        "\n",
        "Пользователь пишет команду /start - функция start() отправляет приветственное сообщение.\n",
        "\n",
        "Пользователь отправляет видео - функция handle_video():\n",
        "\n",
        "* сохраняет видео локально,\n",
        "\n",
        "* открывает его через OpenCV,\n",
        "\n",
        "* проходит по каждому кадру,\n",
        "\n",
        "* прогоняет кадр через YOLO - модель находит объекты,\n",
        "\n",
        "* считает количество людей (cls == 0),\n",
        "\n",
        "* рисует рамки и число людей на кадре,\n",
        "\n",
        "* записывает результат в новое видео.\n",
        "\n",
        "Когда обработка заканчивается:\n",
        "\n",
        "* итоговое видео отправляется обратно пользователю,\n",
        "\n",
        "* временные файлы удаляются, чтобы не захламлять память"
      ],
      "metadata": {
        "id": "8dc0sdzxE2xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "TOKEN = \"8341705487:AAEyJCy1Jq0FIeW6wTPtZO3w5H1JDq0AsgY\"\n",
        "WEIGHTS_PATH = \"best.pt\"\n",
        "OUTPUT_VIDEO = \"output.mp4\"\n",
        "\n",
        "\n",
        "model = YOLO(WEIGHTS_PATH)\n",
        "\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\n",
        "        \"Приветствую. Текущая модель нейросети SecondUpdatedModel.\\n\"\n",
        "        \"Отправьте видеофайл для проверки\"\n",
        "    )\n",
        "\n",
        "\n",
        "async def handle_video(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    video = update.message.video or update.message.document\n",
        "    if not video:\n",
        "        await update.message.reply_text(\"Пожалуйста, отправьте видеофайл\")\n",
        "        return\n",
        "\n",
        "\n",
        "    input_path = \"input.mp4\"\n",
        "    file = await video.get_file()\n",
        "    await file.download_to_drive(input_path)\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "\n",
        "        results = model(frame, conf=0.5)\n",
        "        count = sum(1 for box in results[0].boxes if int(box.cls[0]) == 0)\n",
        "\n",
        "\n",
        "        annotated_frame = results[0].plot()\n",
        "        cv2.putText(annotated_frame, f\"People: {count}\",\n",
        "                    (20, 40), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    1, (0, 255, 0), 2)\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "\n",
        "    with open(OUTPUT_VIDEO, \"rb\") as f:\n",
        "        await update.message.reply_video(f)\n",
        "\n",
        "\n",
        "    os.remove(input_path)\n",
        "    os.remove(OUTPUT_VIDEO)\n",
        "\n",
        "\n",
        "# Запуск бота\n",
        "app = Application.builder().token(TOKEN).build()\n",
        "app.add_handler(CommandHandler(\"start\", start))\n",
        "app.add_handler(MessageHandler(filters.VIDEO | filters.Document.VIDEO, handle_video))\n",
        "\n",
        "await app.run_polling()"
      ],
      "metadata": {
        "id": "CRWuu9vUDHBU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}